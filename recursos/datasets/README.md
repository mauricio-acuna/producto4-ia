# 📊 Datasets Portal 4

Esta carpeta contiene conjuntos de datos curados para cada tipo de capstone del Portal 4.

## 📁 Estructura de Datasets

```
datasets/
├── copiloto-desarrollo/          # Datasets para dev-tools capstone
│   ├── repositorios-codigo/     # Código fuente para análisis
│   ├── documentacion-tecnica/   # Docs de frameworks y APIs
│   ├── issues-prs/             # GitHub issues y pull requests
│   └── vulnerabilidades/       # Ejemplos de code vulnerabilities
├── asistente-empresarial/       # Datasets para RAG corporativo
│   ├── politicas-hr/           # Políticas de recursos humanos
│   ├── manuales-empleado/      # Manuales y procedimientos
│   ├── compliance/             # Documentos de compliance
│   └── faqs-corporativas/      # Preguntas frecuentes
├── legal-finanzas/             # Datasets para domain expert
│   ├── contratos/              # Contratos anonimizados
│   ├── jurisprudencia/         # Casos y precedentes legales
│   ├── regulaciones/           # Normativas y regulaciones
│   └── reportes-financieros/   # Estados financieros
└── analytics-agent/            # Datasets para data intelligence
    ├── ventas-marketing/       # Datos de ventas y marketing
    ├── operaciones/            # Métricas operacionales
    ├── financieros/            # Datos financieros
    └── producto-usuarios/      # Analytics de producto
```

## 🎯 Características de los Datasets

### Calidad y Realismo
- **Datos sintéticos** pero realistas generados con IA
- **Anonimizados** y libres de información sensible
- **Estructurados** para facilitar análisis y benchmarking
- **Escalables** desde prototipos hasta casos complejos

### Metadatos Enriquecidos
- Descripciones detalladas de cada dataset
- Esquemas de datos documentados
- Casos de uso recomendados por dataset
- Niveles de dificultad (básico, intermedio, avanzado)

### Formatos Múltiples
- **Estructurados:** CSV, JSON, Parquet
- **Semi-estructurados:** XML, YAML
- **No estructurados:** PDF, TXT, MD
- **Tiempo real:** Streams simulados

## 🚀 Guía de Uso

### 1. Selección por Capstone
Cada estudiante debe enfocarse en los datasets de su capstone seleccionado, pero puede explorar otros para casos híbridos.

### 2. Progresión de Dificultad
- **Semana 1-2:** Datasets básicos para MVP
- **Semana 3-4:** Datasets intermedios para features avanzadas
- **Semana 4:** Datasets complejos para diferenciación

### 3. Benchmarking
Todos los datasets incluyen ground truth y métricas de evaluación para permitir benchmarking consistente.

## 📋 Checklist de Validación

Antes de usar un dataset, verificar:
- [ ] Compatibilidad con tu capstone seleccionado
- [ ] Nivel de dificultad apropiado para tu semana actual
- [ ] Disponibilidad de ground truth para evaluación
- [ ] Documentación de esquema y metadatos
- [ ] Cumplimiento con requirements de tu stack técnico

## 🔄 Actualizaciones

Los datasets se actualizan regularmente con:
- Nuevos casos de uso identificados por estudiantes
- Mejoras en calidad y realismo
- Correcciones basadas en feedback
- Expansión de cobertura de dominios

---

**💡 Consejo:** Comienza siempre con los datasets básicos de tu capstone antes de avanzar a casos más complejos.
